#!/usr/bin/env python3
# -*- coding: utf-8 -*
import os
import argparse
from utils.merge import merge

BKG_SAMPLE_MAP = {
    "SingleTop": {
        "2016preVFP": ["ST*"],
        "2016postVFP": ["ST*"],
        "2017": ["ST*"],
        "2018": ["ST*"],
    },
    "TTbar1L": {
        "2016preVFP": ["TTToSemiLep*"],
        "2016postVFP": ["TTToSemiLep*"],
        "2017": ["TTToSemiLep*"],
        "2018": ["TTToSemiLep*"],
    },
    "TTbar2L": {
        "2016preVFP": ["TTTo2L*"],
        "2016postVFP": ["TTTo2L*"],
        "2017": ["TTTo2L*"],
        "2018": ["TTTo2L*"],
    },
    "TTX": {
        "2016preVFP": ["ttH*", "TTW*", "TTZ*", "TTbb*", "TTToHadronic*"],
        "2016postVFP": ["ttH*", "TTW*", "TTZ*", "TTbb*", "TTToHadronic*"],
        "2017": ["ttH*", "TTW*", "TTZ*", "TTbb*", "TTToHadronic*"],
        "2018": ["ttH*", "TTW*", "TTZ*", "TTbb*", "TTToHadronic*"],
    },
    "WJets": {
        "2016preVFP": ["WJets*"],
        "2016postVFP": ["WJets*"],
        "2017": ["WJets*"],
        "2018": ["WJets*"],
    },
    "Bosons": {
        "2016preVFP": ["WW*", "WZ*", "ZZ*", "DY*", "EWKW*WToQQ*", "EWKZ*ZToNuNu*", "EWKZ*ZToLL*", "EWKZ*ZToQQ*"],
        "2016postVFP": ["WW*", "WZ*", "ZZ*", "DY*", "EWKW*WToQQ*", "EWKZ*ZToNuNu*", "EWKZ*ZToLL*", "EWKZ*ZToQQ*"],
        "2017": ["WW*", "WZ*", "ZZ*", "DY*", "EWKW*WToQQ*", "EWKZ*ZToNuNu*", "EWKZ*ZToLL*", "EWKZ*ZToQQ*"],
        "2018": ["WW*", "WZ*", "ZZ*", "DY*", "EWKW*WToQQ*", "EWKZ*ZToNuNu*", "EWKZ*ZToLL*", "EWKZ*ZToQQ*"],
    },
    "EWKWLep": {
        "2016preVFP": ["EWKW*WToLNu*"],
        "2016postVFP": ["EWKW*WToLNu*"],
        "2017": ["EWKW*WToLNu*"],
        "2018": ["EWKW*WToLNu*"],
    },
    "VH": {
        "2016preVFP": ["VHToNonbb*", "WminusH*", "WplusH*", "ZH_HToBB*", "ggZH_HToBB*"],
        "2016postVFP": ["VHToNonbb*", "WminusH*", "WplusH*", "ZH_HToBB*", "ggZH_HToBB*"],
        "2017": ["VHToNonbb*", "WminusH*", "WplusH*", "ZH_HToBB*", "ggZH_HToBB*"],
        "2018": ["VHToNonbb*", "WminusH*", "WplusH*", "ZH_HToBB*", "ggZH_HToBB*"],
    }
}

SIG_SAMPLE_MAP = {
    "VBSWH_mkW": {
        "2016preVFP": ["VBSWH_mkW_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2016postVFP": ["VBSWH_mkW_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2017": ["VBSWH_mkW_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2018": ["VBSWH_mkW_Mjj100toInf_Htobb_dipoleRecoilOn"]
    },
}

DATA_SAMPLE_MAP = {
    "data": {
        "2016preVFP": ["*Run201*"],
        "2016postVFP": ["*Run201*"],
        "2017": ["*Run201*"],
        "2018": ["*Run201*"]
    }
}

OTHER_SAMPLE_MAP = {
    "VBSWH_negLambda": {
        "2016preVFP": ["VBSWH_negLambdaWZ_kWkZscan_m2to2_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2016postVFP": ["VBSWH_negLambdaWZ_kWkZscan_m2to2_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2017": ["VBSWH_negLambdaWZ_kWkZscan_m2to2_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2018": ["VBSWH_negLambdaWZ_kWkZscan_m2to2_Mjj100toInf_Htobb_dipoleRecoilOn"]
    },
    "VBSWH_posLambda": {
        "2016preVFP": ["VBSWH_posLambdaWZ_kWkZscan_m2to2_fromBSM_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2016postVFP": ["VBSWH_posLambdaWZ_kWkZscan_m2to2_fromBSM_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2017": ["VBSWH_posLambdaWZ_kWkZscan_m2to2_fromBSM_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2018": ["VBSWH_posLambdaWZ_kWkZscan_m2to2_fromBSM_Mjj100toInf_Htobb_dipoleRecoilOn"]
    },
    "VBSWH_kWkZscan": {
        "2016preVFP": ["VBSWH_kWkZscan_m2to2_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2016postVFP": ["VBSWH_kWkZscan_m2to2_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2017": ["VBSWH_kWkZscan_m2to2_Mjj100toInf_Htobb_dipoleRecoilOn"],
        "2018": ["VBSWH_kWkZscan_m2to2_Mjj100toInf_Htobb_dipoleRecoilOn"]
    },
    "VBSWH_SM": {
        "2016preVFP": ["VBFWH_HToBB_WToLNu_M-125_dipoleRecoilOn"],
        "2016postVFP": ["VBFWH_HToBB_WToLNu_M-125_dipoleRecoilOn"],
        "2017": ["VBFWH_HToBB_WToLNu_M-125_dipoleRecoilOn"],
        "2018": ["VBFWH_HToBB_WToLNu_M-125_dipoleRecoilOn"]
    },
    "VVJJ": {
        "2016preVFP": ["WWJJ*", "WZJJ*", "ZZJJ*"],
        "2016postVFP": ["WWJJ*", "WZJJ*", "ZZJJ*"],
        "2017": ["WWJJ*", "WZJJ*", "ZZJJ*"],
        "2018": ["WWJJ*", "WZJJ*", "ZZJJ*"]
    }
}

if __name__ == "__main__":
    cli = argparse.ArgumentParser(description="Run merge results from /bin/run")
    cli.add_argument(
        "study", type=str,
        help="Name of the study to run"
    )
    cli.add_argument(
        "--tag", type=str, default="",
        help="Unique tag for output"
    )
    cli.add_argument(
        "--terminals", nargs="*",
        help="Names of terminal cuts in cutflow to write to CSV"
    )
    cli.add_argument(
        "--debug", action="store_true",
        help="Run in debug mode"
    )
    cli.add_argument(
        "--n_workers", type=int, default=8,
        help="Number of workers to run hadds"
    )
    cli.add_argument(
        "--basedir", type=str, default="studies",
        help="Base directory for output"
    )
    args = cli.parse_args()

    if args.tag:
        output_dir=f"{args.basedir}/{args.study}/output_{args.tag}"
    else:
        output_dir=f"{args.basedir}/{args.study}/output"

    os.makedirs(f"{output_dir}/Run2", exist_ok=True)

    for year in ["2016preVFP", "2016postVFP", "2017", "2018", "Run2"]:
        if year == "Run2":
            n_workers = args.n_workers
            bkg_sample_map   = BKG_SAMPLE_MAP
            sig_sample_map   = SIG_SAMPLE_MAP
            data_sample_map  = DATA_SAMPLE_MAP
            other_sample_map = OTHER_SAMPLE_MAP
        else:
            n_workers = 0
            bkg_sample_map   = {k: {year: v[year]} for k, v in BKG_SAMPLE_MAP.items()}
            sig_sample_map   = {k: {year: v[year]} for k, v in SIG_SAMPLE_MAP.items()}
            data_sample_map  = {k: {year: v[year]} for k, v in DATA_SAMPLE_MAP.items()}
            other_sample_map = {k: {year: v[year]} for k, v in OTHER_SAMPLE_MAP.items()}

        # Get Cutflow objects for background samples
        cutflows = merge(output_dir, bkg_sample_map, n_hadders=n_workers)
        cutflows["TotalBkg"] = cutflows.sum()
        # Merge data samples and DO NOT save Cutflow object
        cutflows += merge(output_dir, data_sample_map, n_hadders=n_workers)
        # Get Cutflow objects for signal samples
        cutflows += merge(output_dir, sig_sample_map, n_hadders=n_workers)
        cutflows.reorder(["VH", "EWKWLep", "Bosons", "WJets", "SingleTop", "TTX", "TTbar1L", "TTbar2L", "TotalBkg", "VBSWH_mkW", "data"])

        # Write individual cutflows
        if year == "Run2":
            # Write .cflow files
            for group_name, cutflow in cutflows.items():
                cutflow.write_cflow(f"{output_dir}/{year}/{group_name}_cutflow.cflow")
            # Merge other samples
            other_cutflows = merge(output_dir, other_sample_map, n_hadders=n_workers)
            # Write .cflow files
            for group_name, cutflow in other_cutflows.items():
                cutflow.write_cflow(f"{output_dir}/{year}/{group_name}_cutflow.cflow")

        # Write CSV
        cutflows.rename({
            "EWKWLep": "EWK W", 
            "TTX": "TTbar+X", 
            "WJets": "W+Jets", 
            "VBSWH_mkW": "VBSWH (BSM)",
            "VBSWH_SM": "VBSWH (SM)"
        })
        for terminal_cut_name in args.terminals if args.terminals else cutflows.terminal_cut_names:
            cutflows.write_csv(f"{output_dir}/{year}/cutflow_{terminal_cut_name}.csv", terminal_cut_name)
            cutflows.write_txt(f"{output_dir}/{year}/cutflow_{terminal_cut_name}.txt", terminal_cut_name)
            cutflows.write_tex(f"{output_dir}/{year}/cutflow_{terminal_cut_name}.tex", terminal_cut_name)
