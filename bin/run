#!/usr/bin/env python3
# -*- coding: utf-8 -*
import argparse
import glob
import os
import ROOT
from decimal import Decimal
from tools.orchestrator import BabyMakerOrchestrator

class VBSOrchestrator(BabyMakerOrchestrator):
    def __init__(self, year, study, executable, input_files, xsecs_json, n_workers=8, 
                 is_data=False):
        self.output_dir = f"studies/{study}/output/{year}"
        self.is_data = is_data
        if year == 2016:
            self.lumi = 19.52 + 16.81 # preAPV + postAPV
        elif year == 2017:
            self.lumi = 41.48
        elif year == 2018:
            self.lumi = 59.83
        else:
            raise ValueError("year must be 2016, 2017, or 2018")
        os.makedirs(self.output_dir, exist_ok=True)
        super().__init__(executable, input_files, xsecs_json=xsecs_json, n_workers=n_workers)

    def _get_file_info(self, file_name):
        file_info = {
            "is_signal": False,
            "n_events": 0
        }
        if "VBS" in file_name:
            file_info["is_signal"] = True
        if "Run201" in file_name:
            self.is_data = True
        # Get output info
        file_info["output_dir"] = self.output_dir
        file_info["output_name"] = file_name.split('/')[6].split("_Tune")[0]
        if not self.is_data:
            # Get # events
            f = ROOT.TFile(file_name)
            t = f.Get("Runs")
            h = ROOT.TH1F("h", "h", 1, 0, 1)
            t.Draw("0>>h", "genEventSumw", "goff")
            file_info["n_events"] = h.GetBinContent(1)
        return file_info

    def _get_log_files(self, input_file):
        file_info = self._get_file_info(input_file)
        stdout_file = f"{self.output_dir}/{file_info['output_name']}.out"
        stderr_file = f"{self.output_dir}/{file_info['output_name']}.err"
        return stdout_file, stderr_file

    def _get_job(self, input_file):
        file_info = self._get_file_info(input_file)
        cmd = [self.executable]
        cmd.append(f"--input_ttree=Events")
        cmd.append(f"--output_dir={file_info['output_dir']}")
        cmd.append(f"--output_name={file_info['output_name']}")
        if file_info["is_signal"]:
            cmd.append("--is_signal")
        if self.is_data:
            cmd.append("--is_data")
        else:
            xsec = self.get_xsec(input_file)
            sf = xsec*1000*self.lumi/(file_info["n_events"])
            cmd.append(f"--scale_factor={Decimal.from_float(sf)}")
        cmd.append(input_file)
        return cmd

def run_test_jobs():
    dummy_dir = "/nfs-7/userdata/dummy/PhChangSkim/Tag"
    dummy_files = [f"{dummy_dir}/NanoSample{i:02d}_TuneCP5/merged/merged.root" for i in range(1, 11)]
    skims = [(2016, dummy_files), (2017, dummy_files), (2018, dummy_files)]
    for year, files in skims:
        print(f"Orchestrating {year} jobs...")
        orchestrator = VBSOrchestrator(
            year, 
            "dummy",       # study name
            "./bin/dummy", # study executable generated by: make study=[STUDY]
            files,
            xsecs_json="", # JSON with xsec->sample mapping; there is one in data/
            n_workers=8,
            is_data=True   # set this to True so it skips sf calculation
        )
        orchestrator.run()

if __name__ == "__main__":
    vbs_pwd = os.getenv("VBSPWD")
    if vbs_pwd == "":
        print(f"ERROR: `source setup.sh` must be run first")
        exit()
    elif os.getcwd() != vbs_pwd:
        print(f"ERROR: must be run within {vbs_pwd}")
        exit()
    skims = [
        # (2016, glob.glob("/nfs-7/userdata/phchang/NanoSkim/TTHID_3l_v1/*UL16*/merged/*.root")),
        # (2017, glob.glob("/nfs-7/userdata/phchang/NanoSkim/TTHID_3l_v1/*UL17*/merged/*.root")),
        (2018, glob.glob("/nfs-7/userdata/phchang/NanoSkim/TTHID_3l_v1/*UL18*/merged/*.root"))
    ]
    for year, files in skims:
        print(f"Orchestrating {year} jobs...")
        orchestrator = VBSOrchestrator(
            year, 
            "pilot", 
            "./bin/pilot", 
            files, 
            xsecs_json="data/xsecs.json",
            n_workers=8,
            is_data=False
        )
        orchestrator.run()
