#!/usr/bin/env python3
# -*- coding: utf-8 -*
import argparse
import logging
import glob
import json
import os
from subprocess import Popen, PIPE
from decimal import Decimal
from tools.orchestrator import Orchestrator
print("Importing ROOT...")
import ROOT

class VBSOrchestrator(Orchestrator):
    def __init__(self, year, study_name, study_exe, input_files, xsecs_json, n_workers=8):
        self.output_dir = f"studies/{study_name}/output/{year}"
        self.year = year
        if year == "2016preVFP":
            self.lumi = 19.52
        elif year == "2016postVFP":
            self.lumi = 16.81
        elif year == "2017":
            self.lumi = 41.48
        elif year == "2018":
            self.lumi = 59.83
        else:
            raise ValueError("year must be 2016preVFP, 2016postVFP, 2017, or 2018")
        os.makedirs(self.output_dir, exist_ok=True)
        super().__init__(study_exe, input_files, xsecs_json=xsecs_json, n_workers=n_workers)

    def __get_file_info(self, file_name):
        file_info = {}
        file_info["n_events"] = 0
        file_info["is_data"] = ("Run201" in file_name)
        # Get output info
        file_info["output_dir"] = self.output_dir
        file_info["output_name"] = file_name.split("_Tune")[0].split('/')[-1]
        file_info["is_signal"] = ("VBSWH" in file_info["output_name"])
        if not file_info["is_data"]:
            # Get # events
            f = ROOT.TFile(file_name)
            t = f.Get("Runs")
            h = ROOT.TH1F("h", "h", 1, 0, 1)
            t.Draw("0>>h", "genEventSumw", "goff")
            file_info["n_events"] = h.GetBinContent(1)
            f.Close()
        return file_info

    def _get_log_files(self, input_file):
        file_info = self.__get_file_info(input_file)
        stdout_file = f"{self.output_dir}/{file_info['output_name']}.out"
        stderr_file = f"{self.output_dir}/{file_info['output_name']}.err"
        return stdout_file, stderr_file

    def _get_job(self, input_file):
        file_info = self.__get_file_info(input_file)
        with open("data/wjets_ht-binned_xsecs.json", "r") as f_in:
            wjets_xsecs = json.load(f_in)
        cmd = [self.executable]
        cmd.append(f"--input_ttree=Events")
        cmd.append(f"--output_dir={file_info['output_dir']}")
        cmd.append(f"--output_name={file_info['output_name']}")
        if file_info["is_signal"]:
            cmd.append("--is_signal")
        if file_info["is_data"]:
            cmd.append("--is_data")
        else:
            xsec = self.get_xsec(input_file)
            sf = xsec*1000*self.lumi/(file_info["n_events"])
            if "WJetsToLNu_HT-" in file_info["output_name"]:
                sf *= wjets_xsecs[self.year][file_info["output_name"]]
            cmd.append(f"--scale_factor={Decimal.from_float(sf)}")
        cmd.append(input_file)
        return cmd

def run_test_jobs():
    dummy_dir = "/ceph/cms/store/user/dummy/PhChangSkim/Tag"
    dummy_files = [f"{dummy_dir}/NanoSample{i:02d}_TuneCP5/merged/merged.root" for i in range(1, 11)]
    samples = [(2016, dummy_files), (2017, dummy_files), (2018, dummy_files)]
    for year, files in samples:
        print(f"Orchestrating {year} jobs...")
        orchestrator = VBSOrchestrator(
            year, 
            "dummy",       # study name
            "./bin/dummy", # study executable generated by: make study=[STUDY]
            files,
            xsecs_json="", # JSON with xsec->sample mapping; there is one in data/
            n_workers=8
        )
        orchestrator.run()

if __name__ == "__main__":
    cli = argparse.ArgumentParser(description="Run a given study in parallel")
    cli.add_argument(
        "study", type=str,
        help="Name of the study to run"
    )
    cli.add_argument(
        "--n_workers", type=int, default=8,
        help="Maximum number of worker processes"
    )
    cli.add_argument(
        "--nomake", action="store_true",
        help="Do not run make before running the study"
    )
    args = cli.parse_args()

    os.makedirs(f"studies/{args.study}/output", exist_ok=True)
    logging.basicConfig(
        filename=f"studies/{args.study}/output/run.log",
        filemode="w",
        format="%(levelname)s [%(asctime)s]: %(message)s",
        datefmt="%m-%d-%Y %H:%M:%S %p",
        level="DEBUG"
    )

    if not args.nomake:
        print(f"make study={args.study} clean")
        Popen(f"make study={args.study} clean".split(), stdout=PIPE).wait()
        print(f"make study={args.study}")
        stdout, stderr = Popen(f"make study={args.study}".split(), stdout=PIPE, stderr=PIPE).communicate()
        if stderr:
            raise RuntimeError(
                f"make --study={args.study} failed with the following error\n\n"
                + stderr.decode("utf-8")
            )

    # Check that the PWD is correct
    vbs_pwd = os.getenv("VBSPWD")
    if vbs_pwd == "":
        print(f"ERROR: `source setup.sh` must be run first")
        exit()
    elif os.getcwd() != vbs_pwd:
        print(f"ERROR: must be run within {vbs_pwd}")
        exit()

    # Gather samples
    ceph_dir = "/ceph/cms/store/user/jguiang"
    skim = "VBSVHSkim/1lep_1ak8_2ak4_v1"
    samples = {"2016preVFP": [], "2016postVFP": [], "2017": [], "2018": []}
    # Add background samples
    samples["2016preVFP"] += glob.glob(f"{ceph_dir}/{skim}/*UL16NanoAODAPVv9*/merged.root")
    samples["2016postVFP"] += glob.glob(f"{ceph_dir}/{skim}/*UL16NanoAODv9*/merged.root")
    samples["2017"] += glob.glob(f"{ceph_dir}/{skim}/*UL17NanoAODv9*/merged.root")
    samples["2018"] += glob.glob(f"{ceph_dir}/{skim}/*UL18NanoAODv9*/merged.root")
    # Add signal samples
    samples["2016preVFP"].append(f"{ceph_dir}/VBSWHSignalGeneration/v1/VBSWH_mkW_Inclusive_TuneCP5_RunIISummer20UL16APV-106X_privateMC_NANOGEN_v1/merged.root")
    samples["2016postVFP"].append(f"{ceph_dir}/VBSWHSignalGeneration/v1/VBSWH_mkW_Inclusive_TuneCP5_RunIISummer20UL16-106X_privateMC_NANOGEN_v1/merged.root")
    samples["2017"].append(f"{ceph_dir}/VBSWHSignalGeneration/v1/VBSWH_mkW_Inclusive_TuneCP5_RunIISummer20UL16-106X_privateMC_NANOGEN_v1/merged.root")
    samples["2018"].append(f"{ceph_dir}/VBSWHSignalGeneration/v1/VBSWH_mkW_Inclusive_TuneCP5_RunIISummer20UL18-106X_privateMC_NANOGEN_v1/merged.root")
    for year, files in samples.items():
        print(f"Orchestrating {year} jobs...")
        # Run study
        orchestrator = VBSOrchestrator(
            year, 
            args.study, 
            f"./bin/{args.study}", 
            files, 
            xsecs_json="data/xsecs.json",
            n_workers=args.n_workers
        )
        orchestrator.run()
